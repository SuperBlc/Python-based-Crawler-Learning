{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# urllib库\n",
    "\n",
    "urllib是Python中最基本的网络请求库。可以模拟浏览器行为，向指定的服务器发送请求，并保存服务器返回的数据。\n",
    "\n",
    "## urllib中包含的模块\n",
    "\n",
    "1. urllib.request：用于发起并读取URLS\n",
    "2. urllib.error：用于处理由urllib.request抛出的异常\n",
    "3. urllib.parse： url解析\n",
    "4. urllib.robotparser： robots.txt解析\n",
    "\n",
    "## urllib.request常用函数\n",
    "\n",
    "### urlopen函数\n",
    "\n",
    "函数及参数:\n",
    "\n",
    "```python\n",
    "urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None)\n",
    "```\n",
    "\n",
    "在Python3的urllib库中，所有和网站请求相关的方法，都集成到了```urllib.request```模块中，以下是相关示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "状态码： 200\n",
      "\n",
      "--------------------分割线--------------------\n",
      "\n",
      "读取到的内容（不解码）：\n",
      " b'{\\n  \"args\": {}, \\n  \"headers\": {\\n    \"Accept-Encoding\": \"identity\", \\n    \"Connection\": \"close\", \\n    \"Host\": \"localhost\", \\n    \"User-Agent\": \"Python-urllib/3.5\"\\n  }, \\n  \"origin\": \"172.17.0.1\", \\n  \"url\": \"http://localhost/get\"\\n}\\n'\n",
      "\n",
      "--------------------分割线--------------------\n",
      "\n",
      "读取到的内容（用utf-8解码）：\n",
      " {\n",
      "  \"args\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept-Encoding\": \"identity\", \n",
      "    \"Connection\": \"close\", \n",
      "    \"Host\": \"localhost\", \n",
      "    \"User-Agent\": \"Python-urllib/3.5\"\n",
      "  }, \n",
      "  \"origin\": \"172.17.0.1\", \n",
      "  \"url\": \"http://localhost/get\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "\n",
    "'''\n",
    "    打开一个url\n",
    "'''\n",
    "\n",
    "# urlopen的返回对象是一个http.client.HttpResponse对象，是一个类文件句柄\n",
    "req = request.urlopen('http://localhost/get') # http://www.httpbin.org/get\n",
    "\n",
    "print('状态码：', req.getcode())\n",
    "print('\\n--------------------分割线--------------------\\n')\n",
    "text = req.read()\n",
    "print('读取到的内容（不解码）：\\n', text)\n",
    "print('\\n--------------------分割线--------------------\\n')\n",
    "print('读取到的内容（用utf-8解码）：\\n', text.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"args\": {}, \n",
      "  \"data\": \"\", \n",
      "  \"files\": {}, \n",
      "  \"form\": {\n",
      "    \"date\": \"2019-07-25\", \n",
      "    \"message\": \"Hello, httpbin. This is from urllib\"\n",
      "  }, \n",
      "  \"headers\": {\n",
      "    \"Accept-Encoding\": \"identity\", \n",
      "    \"Connection\": \"close\", \n",
      "    \"Content-Length\": \"61\", \n",
      "    \"Content-Type\": \"application/x-www-form-urlencoded\", \n",
      "    \"Host\": \"localhost\", \n",
      "    \"User-Agent\": \"Python-urllib/3.5\"\n",
      "  }, \n",
      "  \"json\": null, \n",
      "  \"origin\": \"172.17.0.1\", \n",
      "  \"url\": \"http://localhost/post\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib import parse\n",
    "from urllib import request\n",
    "\n",
    "'''\n",
    "    设置data参数\n",
    "'''\n",
    "data = bytes(parse.urlencode({\"message\":\"Hello, httpbin. This is from urllib\",\"date\":\"2019-07-25\"}), encoding='utf8')\n",
    "# https://httpbin.org/post\n",
    "response = request.urlopen(\"http://localhost/post\", data=data)\n",
    "print(response.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get code: 200 . No Exception\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "\n",
    "'''\n",
    "    设置超时参数timeout\n",
    "'''\n",
    "\n",
    "res = request.urlopen(\"https://baidu.com\", timeout=1)\n",
    "print('Get code:',res.getcode(),'. No Exception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception:  _ssl.c:630: The handshake operation timed out\n"
     ]
    }
   ],
   "source": [
    "from urllib import request, error\n",
    "import socket\n",
    "\n",
    "try:\n",
    "    response = request.urlopen(\"https://httpbin.org\", timeout=0.2)\n",
    "except error.URLError as e:\n",
    "    if isinstance(e.reason, socket.timeout):\n",
    "        print(\"Exception: \",e.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 响应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "响应类型： <class 'http.client.HTTPResponse'>\n",
      "\n",
      "状态码： 200\n",
      "\n",
      "响应头：\n",
      "gunicorn/19.9.0\n",
      "[('Server', 'gunicorn/19.9.0'), ('Date', 'Thu, 25 Jul 2019 08:09:13 GMT'), ('Connection', 'close'), ('Content-Type', 'text/html; charset=utf-8'), ('Content-Length', '9593'), ('Access-Control-Allow-Origin', '*'), ('Access-Control-Allow-Credentials', 'true')]\n"
     ]
    }
   ],
   "source": [
    "from urllib import request\n",
    "\n",
    "# 响应类型\n",
    "res = request.urlopen('http://localhost')\n",
    "print(\"响应类型：\", type(res))\n",
    "\n",
    "# 状态码\n",
    "print('\\n状态码：', res.status)\n",
    "\n",
    "# 响应头\n",
    "print(\"\\n响应头：\")\n",
    "print(res.getheader('Server'))\n",
    "print(res.getheaders())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"args\": {}, \n",
      "  \"data\": \"\", \n",
      "  \"files\": {}, \n",
      "  \"form\": {\n",
      "    \"date\": \"2019-07-25\", \n",
      "    \"day_of_outing\": \"10\", \n",
      "    \"message\": \"Go to the world\", \n",
      "    \"title\": \"For more test\"\n",
      "  }, \n",
      "  \"headers\": {\n",
      "    \"Accept-Encoding\": \"identity\", \n",
      "    \"Connection\": \"close\", \n",
      "    \"Content-Length\": \"76\", \n",
      "    \"Content-Type\": \"application/x-www-form-urlencoded\", \n",
      "    \"Host\": \"localhost\", \n",
      "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.18362\"\n",
      "  }, \n",
      "  \"json\": null, \n",
      "  \"origin\": \"172.17.0.1\", \n",
      "  \"url\": \"http://localhost/post\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib import request, parse\n",
    "\n",
    "url = \"http://localhost/post\"\n",
    "headers = {\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.18362',\n",
    "    'Host':'localhost'\n",
    "}\n",
    "data = {\n",
    "    'title':'For more test',\n",
    "    'date':'2019-07-25',\n",
    "    'message':'Go to the world',\n",
    "    'day_of_outing' : 10\n",
    "}\n",
    "byte_data = bytes(parse.urlencode(data), encoding='utf8')\n",
    "req = request.Request(url, data=byte_data,headers=headers, method='POST')\n",
    "res = request.urlopen(req)\n",
    "print(res.read().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 代理设置\n",
    "from urllib import  request\n",
    "\n",
    "proxy_handler = request.ProxyHandler({\n",
    "    'http':'192.168.88.4:1080',\n",
    "    'https':'192.168.88.4:1080'\n",
    "})\n",
    "opener = request.build_opener(proxy_handler)\n",
    "res = opener.open('https://httpbin.org/')\n",
    "print(response.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cookie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.cookiejar, urllib.request\n",
    "'''\n",
    "读取对应网站存储在本地的Cookie\n",
    "'''\n",
    "cookie = http.cookiejar.CookieJar()\n",
    "handler = urllib.request.HTTPCookieProcessor(cookie)\n",
    "opener = urllib.request.build_opener(handler)\n",
    "response = request.urlopen(\"https://weibo.com\")\n",
    "for item in cookie:\n",
    "    print(item.name+\"=\"+item.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.cookiejar, urllib.request\n",
    "\n",
    "'''\n",
    "将cookie存储在文件中\n",
    "'''\n",
    "filename=\"cookie.txt\"\n",
    "cookie = http.cookiejar.LWPCookieJar(filename)\n",
    "handler = urllib.request.HTTPCookieProcessor(cookie)\n",
    "opener = urllib.request.build_opener(handler)\n",
    "response = request.urlopen(\"https://weibo.com\")\n",
    "cookie.save(ignore_discard=True,ignore_expires=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.cookiejar, urllib.request\n",
    "\n",
    "'''\n",
    "读取保存的Cookie\n",
    "'''\n",
    "cookie = http.cookiejar.LWPCookieJar(filename)\n",
    "# 从文件中加载之前保存的cookie\n",
    "cookie.load('cookie.txt', ignore_discard=True,ignore_expires=True)\n",
    "handler = urllib.request.HTTPCookieProcessor(cookie)\n",
    "opener = urllib.request.build_opener(handler)\n",
    "response = request.urlopen(\"https://weibo.com\")\n",
    "cookie.save(ignore_discard=True,ignore_expires=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 异常处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 11001] getaddrinfo failed\n",
      "Not Found\n"
     ]
    }
   ],
   "source": [
    "from urllib import request,error\n",
    "\n",
    "try:\n",
    "    request.urlopen('http://asdasdasdsadasdm.abs')\n",
    "except error.URLError as e:\n",
    "    print(e.reason)\n",
    "    \n",
    "try:\n",
    "    request.urlopen('https://heymax.site/about')\n",
    "except error.URLError as e:\n",
    "    print(e.reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Found\n",
      "\n",
      "404\n",
      "\n",
      "Server: nginx/1.14.2\n",
      "Date: Thu, 25 Jul 2019 08:09:29 GMT\n",
      "Content-Type: text/html\n",
      "Content-Length: 0\n",
      "Connection: close\n",
      "ETag: \"5c6cb500-0\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib import request,error\n",
    "\n",
    "try:\n",
    "    request.urlopen('https://heymax.site/article')\n",
    "except error.HTTPError as e:\n",
    "    print(e.reason, e.code, e.headers, sep='\\n\\n')\n",
    "except error.URLError as e:\n",
    "    print(e.reason)\n",
    "else:\n",
    "    print('Request Successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'socket.gaierror'>\n"
     ]
    }
   ],
   "source": [
    "from urllib import request,error\n",
    "\n",
    "# 捕获两种异常，HTTPError和URLError\n",
    "# 访问的网址存在，但是请求的页面不不存在\n",
    "try:\n",
    "    request.urlopen('https://heymax.site/article')\n",
    "except error.HTTPError as e:\n",
    "    print(type(e.reason))\n",
    "    \n",
    "try:\n",
    "    request.urlopen('https://heymax.site/article')\n",
    "except error.URLError as e:\n",
    "    print(type(e.reason))\n",
    "\n",
    "\n",
    "# 访问的网址不存在\n",
    "# 异常属于'socket.gaierror'类型\n",
    "try:\n",
    "    request.urlopen('https://heymasdsad.asde/article')\n",
    "except error.URLError as e:\n",
    "    print(type(e.reason))\n",
    "    \n",
    "# 访问的网址存在，捕获超时异常\n",
    "# 超时异常属于'socket.timeout'类型\n",
    "try:\n",
    "    request.urlopen('https://heymax.site', timeout=0.1)\n",
    "except error.URLError as e:\n",
    "    print(type(e.reason))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## urllib.parse常用函数（URL解析）\n",
    "\n",
    "### urlparse\n",
    "\n",
    "```python\n",
    "urllib.parse.urlparse(urlstring, scheme='', allow_fragments=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParseResult(scheme='http', netloc='www.baidu.com', path='/index.html', params='user=5', query='', fragment='comment')\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "result = urlparse(\"http://www.baidu.com/index.html;user=5#comment\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParseResult(scheme='https', netloc='', path='www.baidu.com/index.html', params='user=5', query='', fragment='comment')\n",
      "ParseResult(scheme='http', netloc='www.baidu.com', path='/index.html', params='user=5', query='', fragment='comment')\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "# scheme : 协议类型\n",
    "# 如果url中不带有协议类型，则指定scheme后，会按照scheme填上\n",
    "result = urlparse(\"www.baidu.com/index.html;user=5#comment\",scheme=\"https\")\n",
    "print(result)\n",
    "\n",
    "result = urlparse(\"http://www.baidu.com/index.html;user=5#comment\", scheme=\"https\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParseResult(scheme='https', netloc='', path='www.baidu.com/index.html', params='user=5#comment', query='', fragment='')\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "# 当allow_fragment为False，fragment的内容为空\n",
    "result = urlparse(\"www.baidu.com/index.html;user=5#comment\",scheme=\"https\", allow_fragments=False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParseResult(scheme='https', netloc='www.baidu.com', path='/index.html#comment', params='', query='', fragment='')\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "# 当allow_fragment为False，则会按照query，path是否为空，依次拼接。\n",
    "# 当query不为空时，fragment的内容会拼接到query中\n",
    "# 当query为空，path不为空时，fragment的内容会拼接到path中\n",
    "result = urlparse(\"https://www.baidu.com/index.html#comment\", allow_fragments=False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### urlunparse\n",
    "\n",
    "从一个元组/数组中拼接出url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.baidu.com/api;user?name=jeryy#comment\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlunparse\n",
    "\n",
    "# 元组/数组的长度不得超过6\n",
    "url_block = ('http','www.baidu.com','api','user','name=jeryy','comment')\n",
    "print(urlunparse(url_block))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### urljoin\n",
    "\n",
    "url拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://heymax.site\n",
      "http://www.baidu.com\n",
      "https://heymax.site/about-me\n",
      "https://heymax.site/about-me?categray=happy\n",
      "https://heymax.site/about-me\n",
      "https://heymax.site/about-me?categray=education\n",
      "https://heymax.site/?categray=education\n",
      "heymax.site?categray=education\n",
      "heymax.site?categray=education#comment\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urljoin\n",
    "\n",
    "print(urljoin('http://www.baidu.com','https://heymax.site'))\n",
    "print(urljoin('https://heymax.site/about-me','http://www.baidu.com'))\n",
    "print(urljoin('http://www.baidu.com/about','https://heymax.site/about-me'))\n",
    "print(urljoin('http://www.baidu.com/about','https://heymax.site/about-me?categray=happy'))\n",
    "print(urljoin('http://www.baidu.com/about?word=asbc','https://heymax.site/about-me'))\n",
    "print(urljoin('https://heymax.site/about-me','?categray=education'))\n",
    "print(urljoin('https://heymax.site/#today','?categray=education'))\n",
    "print(urljoin('heymax.site','?categray=education'))\n",
    "print(urljoin('heymax.site','?categray=education#comment'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### urlencode\n",
    "\n",
    "url编码，可将字典类型转换为get参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://heymax.site/lookup?age=33&name=Jerry\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlencode\n",
    "\n",
    "params = {\n",
    "    'name':'Jerry',\n",
    "    'age':33\n",
    "}\n",
    "base_url = 'https://heymax.site/lookup?'\n",
    "url = base_url + urlencode(params)\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## urllib.robotparser\n",
    "\n",
    "urllib.robotparser模块只提供一个类 `RobotFileParser`，用来读取，解析，回答robots.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.robotparser import RobotFileParser\n",
    "\n",
    "rp = RobotFileParser()\n",
    "rp.set_url(\"http://www.musi-cal.com/robots.txt\")\n",
    "rfile_url = rp.read()\n",
    "# rrate = rp.crawl_delay(\"*\")\n",
    "# rrate.requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
